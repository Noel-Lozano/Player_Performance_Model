{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "\n",
      "Loading datasets...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/nba_player_game_logs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-990647907.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load historical data (NBA API)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistorical_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/nba_player_game_logs.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✓ Historical data loaded: {len(historical_df)} games\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/nba_player_game_logs.csv'"
     ]
    }
   ],
   "source": [
    "# NBA Props Predictor - Data Exploration & Cleaning\n",
    "# Notebook 02: Load, Clean, and Understand Your Data\n",
    "\n",
    "# STEP 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n",
    "# STEP 2: Load Data\n",
    "print(\"\\nLoading datasets...\")\n",
    "\n",
    "# Load historical data (NBA API)\n",
    "historical_df = pd.read_csv('nba_player_game_logs.csv')\n",
    "print(f\"✓ Historical data loaded: {len(historical_df)} games\")\n",
    "\n",
    "# Load current season (ESPN) - if it exists\n",
    "try:\n",
    "    current_df = pd.read_csv('nba_current_season_2025_26.csv')\n",
    "    print(f\"✓ Current season loaded: {len(current_df)} games\")\n",
    "    \n",
    "    # Combine datasets\n",
    "    df = pd.concat([historical_df, current_df], ignore_index=True)\n",
    "    print(f\"✓ Combined dataset: {len(df)} total games\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Current season file not found, using historical data only\")\n",
    "    df = historical_df\n",
    "\n",
    "# Convert GAME_DATE to datetime\n",
    "df['GAME_DATE'] = pd.to_datetime(df['GAME_DATE'])\n",
    "\n",
    "# STEP 3: Standardize Player Names (Remove Special Characters)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STANDARDIZING PLAYER NAMES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Map special characters to standard ASCII\n",
    "player_name_mapping = {\n",
    "    'Nikola Jokić': 'Nikola Jokic',\n",
    "    'Nikola Vučević': 'Nikola Vucevic',\n",
    "    'Luka Dončić': 'Luka Doncic',\n",
    "    'Kristaps Porziņģis': 'Kristaps Porzingis',\n",
    "    'Dāvis Bertāns': 'Davis Bertans',\n",
    "    'Bogdan Bogdanović': 'Bogdan Bogdanovic',\n",
    "    'Nikola Jović': 'Nikola Jovic',\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "df['PLAYER_NAME'] = df['PLAYER_NAME'].replace(player_name_mapping)\n",
    "\n",
    "print(\"✓ Player names standardized\")\n",
    "print(\"\\nPlayers affected:\")\n",
    "for old_name, new_name in player_name_mapping.items():\n",
    "    count = len(df[df['PLAYER_NAME'] == new_name])\n",
    "    if count > 0:\n",
    "        print(f\"  {old_name} → {new_name}: {count} games\")\n",
    "\n",
    "# STEP 4: Fix Team Abbreviations and Match Opponent Stats\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIXING OPPONENT DEFENSIVE STATS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load team stats\n",
    "try:\n",
    "    team_stats = pd.read_csv('nba_team_stats.csv')\n",
    "    print(f\"✓ Loaded team stats: {len(team_stats)} team-seasons\")\n",
    "    \n",
    "    # Check missing opponent stats before fixing\n",
    "    missing_before = df['OPP_DEF_RATING'].isna().sum() if 'OPP_DEF_RATING' in df.columns else len(df)\n",
    "    print(f\"\\nOpponent stats missing: {missing_before} games ({missing_before/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # ESPN vs NBA API team abbreviation differences\n",
    "    team_abbrev_mapping = {\n",
    "        'BKN': 'BRK',   # Brooklyn Nets\n",
    "        'CHA': 'CHO',   # Charlotte Hornets (sometimes CHH)\n",
    "        'PHX': 'PHO',   # Phoenix Suns\n",
    "        'SA': 'SAS',    # San Antonio Spurs\n",
    "        'GS': 'GSW',    # Golden State Warriors\n",
    "        'NO': 'NOP',    # New Orleans Pelicans\n",
    "        'NY': 'NYK',    # New York Knicks\n",
    "        'UTAH': 'UTA',  # Utah Jazz\n",
    "        'WSH': 'WAS',   # Washington Wizards\n",
    "    }\n",
    "    \n",
    "    # Create OPPONENT_FIXED column\n",
    "    if 'OPPONENT' in df.columns:\n",
    "        df['OPPONENT_FIXED'] = df['OPPONENT'].replace(team_abbrev_mapping)\n",
    "    else:\n",
    "        print(\"⚠ OPPONENT column not found, creating from MATCHUP\")\n",
    "        # Extract opponent from MATCHUP if needed\n",
    "        def extract_opponent(matchup):\n",
    "            if 'vs.' in str(matchup):\n",
    "                return matchup.split('vs.')[-1].strip()\n",
    "            elif '@' in str(matchup):\n",
    "                return matchup.split('@')[-1].strip()\n",
    "            return None\n",
    "        df['OPPONENT'] = df['MATCHUP'].apply(extract_opponent)\n",
    "        df['OPPONENT_FIXED'] = df['OPPONENT'].replace(team_abbrev_mapping)\n",
    "    \n",
    "    # Find correct team abbreviation column in team_stats\n",
    "    team_col = None\n",
    "    if 'TEAM_ABBREVIATION' in team_stats.columns:\n",
    "        team_col = 'TEAM_ABBREVIATION'\n",
    "    elif 'TEAM_ABBRV' in team_stats.columns:\n",
    "        team_col = 'TEAM_ABBRV'\n",
    "    else:\n",
    "        # Create from team names using NBA API\n",
    "        print(\"  Creating team abbreviations from team names...\")\n",
    "        from nba_api.stats.static import teams\n",
    "        team_list = teams.get_teams()\n",
    "        team_mapping_dict = {t['full_name']: t['abbreviation'] for t in team_list}\n",
    "        team_stats['TEAM_ABBREVIATION'] = team_stats['TEAM_NAME'].map(team_mapping_dict)\n",
    "        team_col = 'TEAM_ABBREVIATION'\n",
    "    \n",
    "    print(f\"  Using team column: {team_col}\")\n",
    "    \n",
    "    # Prepare opponent stats for merging\n",
    "    opp_stats = team_stats[[team_col, 'SEASON', 'DEF_RATING', 'PACE']].copy()\n",
    "    opp_stats.columns = ['OPPONENT_FIXED', 'SEASON', 'OPP_DEF_RATING_NEW', 'OPP_PACE_NEW']\n",
    "    \n",
    "    # Remove old opponent stats columns if they exist\n",
    "    df = df.drop(columns=['OPP_DEF_RATING', 'OPP_PACE'], errors='ignore')\n",
    "    \n",
    "    # Merge with correct team abbreviations\n",
    "    df = df.merge(opp_stats, on=['OPPONENT_FIXED', 'SEASON'], how='left')\n",
    "    df = df.rename(columns={\n",
    "        'OPP_DEF_RATING_NEW': 'OPP_DEF_RATING',\n",
    "        'OPP_PACE_NEW': 'OPP_PACE'\n",
    "    })\n",
    "    \n",
    "    # Check improvement\n",
    "    still_missing = df['OPP_DEF_RATING'].isna().sum()\n",
    "    fixed_count = missing_before - still_missing\n",
    "    print(f\"\\n✓ Fixed {fixed_count} opponent matchings\")\n",
    "    print(f\"  Still missing: {still_missing} games ({still_missing/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Show which opponents are still missing\n",
    "    if still_missing > 0:\n",
    "        print(\"\\n  Opponents still missing stats:\")\n",
    "        missing_opponents = df[df['OPP_DEF_RATING'].isna()]['OPPONENT_FIXED'].value_counts()\n",
    "        print(missing_opponents.head(10))\n",
    "    \n",
    "    # Fill remaining missing with league averages\n",
    "    if still_missing > 0:\n",
    "        league_avg_def = df['OPP_DEF_RATING'].mean()\n",
    "        league_avg_pace = df['OPP_PACE'].mean()\n",
    "        df['OPP_DEF_RATING'].fillna(league_avg_def, inplace=True)\n",
    "        df['OPP_PACE'].fillna(league_avg_pace, inplace=True)\n",
    "        print(f\"\\n  ✓ Filled remaining with league averages:\")\n",
    "        print(f\"    DEF_RATING: {league_avg_def:.2f}\")\n",
    "        print(f\"    PACE: {league_avg_pace:.2f}\")\n",
    "    \n",
    "    print(\"\\n✓ Opponent defensive ratings distribution:\")\n",
    "    print(df['OPP_DEF_RATING'].describe())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ Team stats file not found, skipping opponent stats merge\")\n",
    "\n",
    "# STEP 5: Data Cleaning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "original_rows = len(df)\n",
    "\n",
    "# Drop columns with >90% missing (not useful for modeling)\n",
    "high_missing_threshold = 0.9\n",
    "cols_to_check = df.columns\n",
    "high_missing_cols = []\n",
    "\n",
    "for col in cols_to_check:\n",
    "    missing_pct = df[col].isna().sum() / len(df)\n",
    "    if missing_pct > high_missing_threshold:\n",
    "        high_missing_cols.append(col)\n",
    "\n",
    "if high_missing_cols:\n",
    "    df = df.drop(columns=high_missing_cols)\n",
    "    print(f\"✓ Dropped {len(high_missing_cols)} columns with >{high_missing_threshold*100}% missing:\")\n",
    "    for col in high_missing_cols:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "# Fill shooting percentages with 0 (for games with 0 attempts)\n",
    "shooting_cols = ['FG_PCT', 'FG3_PCT', 'FT_PCT']\n",
    "for col in shooting_cols:\n",
    "    if col in df.columns:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "print(f\"\\n✓ Filled shooting percentages (0 for no attempts)\")\n",
    "\n",
    "# Drop rows missing critical stats\n",
    "critical_cols = ['PTS', 'REB', 'AST', 'MIN', 'PLAYER_NAME', 'GAME_DATE']\n",
    "existing_critical = [col for col in critical_cols if col in df.columns]\n",
    "before_drop = len(df)\n",
    "df = df.dropna(subset=existing_critical)\n",
    "dropped_rows = before_drop - len(df)\n",
    "if dropped_rows > 0:\n",
    "    print(f\"✓ Dropped {dropped_rows} rows missing critical stats ({dropped_rows/original_rows*100:.1f}%)\")\n",
    "\n",
    "# Fill remaining common missing values\n",
    "if 'IS_HOME' in df.columns:\n",
    "    df['IS_HOME'].fillna(0, inplace=True)\n",
    "\n",
    "if 'PLUS_MINUS' in df.columns:\n",
    "    df['PLUS_MINUS'].fillna(0, inplace=True)\n",
    "\n",
    "if 'WL' in df.columns:\n",
    "    df['WL'].fillna('L', inplace=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CLEANED DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Original rows: {original_rows:,}\")\n",
    "print(f\"Cleaned rows: {len(df):,}\")\n",
    "print(f\"Rows removed: {original_rows - len(df):,} ({(original_rows - len(df))/original_rows*100:.1f}%)\")\n",
    "print(f\"\\nMissing values remaining: {df.isnull().sum().sum()}\")\n",
    "\n",
    "remaining_missing = df.isnull().sum()\n",
    "if remaining_missing.sum() > 0:\n",
    "    print(\"\\nColumns still with missing values:\")\n",
    "    missing_df = remaining_missing[remaining_missing > 0].sort_values(ascending=False)\n",
    "    for col, count in missing_df.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {col}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\n✓ No missing values in critical columns!\")\n",
    "\n",
    "# STEP 6: Basic Data Info\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nShape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Date range: {df['GAME_DATE'].min().date()} to {df['GAME_DATE'].max().date()}\")\n",
    "print(f\"Unique players: {df['PLAYER_NAME'].nunique()}\")\n",
    "if 'SEASON' in df.columns:\n",
    "    print(f\"Seasons: {sorted(df['SEASON'].unique())}\")\n",
    "\n",
    "print(\"\\nKey columns available:\")\n",
    "key_cols = ['PLAYER_NAME', 'GAME_DATE', 'PTS', 'REB', 'AST', 'MIN', 'OPPONENT', \n",
    "            'OPP_DEF_RATING', 'OPP_PACE', 'IS_HOME', 'WL']\n",
    "for col in key_cols:\n",
    "    status = \"✓\" if col in df.columns else \"✗\"\n",
    "    print(f\"  {status} {col}\")\n",
    "\n",
    "# STEP 7: Games Per Player\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GAMES PER PLAYER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "games_per_player = df.groupby('PLAYER_NAME').size().sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 players by games:\")\n",
    "print(games_per_player.head(10))\n",
    "\n",
    "print(f\"\\nBottom 10 players by games:\")\n",
    "print(games_per_player.tail(10))\n",
    "\n",
    "print(f\"\\nGames per player statistics:\")\n",
    "print(games_per_player.describe())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 6))\n",
    "games_per_player.head(20).plot(kind='bar', color='steelblue')\n",
    "plt.title('Top 20 Players by Number of Games', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Player', fontsize=12)\n",
    "plt.ylabel('Number of Games', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# STEP 8: Statistical Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "key_stats = ['MIN', 'PTS', 'REB', 'AST', 'STL', 'BLK', 'TOV', \n",
    "             'FG_PCT', 'FG3_PCT', 'FT_PCT', 'OPP_DEF_RATING', 'OPP_PACE']\n",
    "available_stats = [stat for stat in key_stats if stat in df.columns]\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df[available_stats].describe().round(2))\n",
    "\n",
    "# STEP 9: Points Distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POINTS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nPoints statistics:\")\n",
    "print(df['PTS'].describe())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['PTS'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0].set_title('Distribution of Points Scored', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Points')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].axvline(df['PTS'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"PTS\"].mean():.1f}')\n",
    "axes[0].axvline(df['PTS'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[\"PTS\"].median():.1f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['PTS'], vert=True)\n",
    "axes[1].set_title('Points Box Plot', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Points')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# STEP 10: Top Performers\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP PERFORMERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate averages (min 20 games)\n",
    "player_stats = df.groupby('PLAYER_NAME').agg({\n",
    "    'PTS': ['mean', 'std', 'count'],\n",
    "    'REB': 'mean',\n",
    "    'AST': 'mean',\n",
    "    'MIN': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "player_stats.columns = ['PTS_AVG', 'PTS_STD', 'GAMES', 'REB_AVG', 'AST_AVG', 'MIN_AVG']\n",
    "player_stats = player_stats[player_stats['GAMES'] >= 20].sort_values('PTS_AVG', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 scorers (min 20 games):\")\n",
    "print(player_stats.head(15))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_15 = player_stats.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['PTS_AVG'], xerr=top_15['PTS_STD'], \n",
    "         alpha=0.7, capsize=5, color='coral')\n",
    "plt.yticks(range(len(top_15)), top_15.index)\n",
    "plt.xlabel('Average Points Per Game', fontsize=12)\n",
    "plt.title('Top 15 Scorers (with Std Dev)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# STEP 11: Correlation Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "corr_stats = ['PTS', 'REB', 'AST', 'STL', 'BLK', 'MIN', 'FGA', 'FG_PCT', \n",
    "              'FG3A', 'FG3_PCT', 'OPP_DEF_RATING', 'OPP_PACE']\n",
    "corr_stats = [col for col in corr_stats if col in df.columns]\n",
    "\n",
    "correlation_matrix = df[corr_stats].corr()\n",
    "\n",
    "print(\"\\nCorrelation with Points:\")\n",
    "print(correlation_matrix['PTS'].sort_values(ascending=False))\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# STEP 12: Save Cleaned Data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING CLEANED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "output_file = 'nba_player_game_logs_cleaned.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"✓ Cleaned data saved to: {output_file}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "\n",
    "# STEP 13: Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Dataset Summary:\n",
    "  • Total games: {len(df):,}\n",
    "  • Unique players: {df['PLAYER_NAME'].nunique()}\n",
    "  • Date range: {df['GAME_DATE'].min().date()} to {df['GAME_DATE'].max().date()}\n",
    "  • Avg points: {df['PTS'].mean():.1f} ± {df['PTS'].std():.1f}\n",
    "  • Avg rebounds: {df['REB'].mean():.1f} ± {df['REB'].std():.1f}\n",
    "  • Avg assists: {df['AST'].mean():.1f} ± {df['AST'].std():.1f}\n",
    "\n",
    "Data Quality:\n",
    "  • Missing values: {df.isnull().sum().sum()}\n",
    "  • Opponent stats coverage: {(1 - df['OPP_DEF_RATING'].isna().sum()/len(df))*100:.1f}%\n",
    "  \n",
    "✓ Ready for feature engineering!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nNext step: Run 03_feature_engineering.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missing values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REMAINING MISSING VALUES BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing': missing.values,\n",
    "    'Percentage': (missing.values / len(df) * 100).round(2)\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False)\n",
    "\n",
    "print(f\"\\nColumns with missing values:\")\n",
    "print(missing_df.to_string(index=False))\n",
    "\n",
    "# Categorize by importance\n",
    "critical_stats = ['PTS', 'REB', 'AST', 'MIN']\n",
    "important_stats = ['FGM', 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'STL', 'BLK', 'TOV']\n",
    "contextual_stats = ['OPP_DEF_RATING', 'OPP_PACE', 'IS_HOME', 'OPPONENT']\n",
    "non_essential = ['VIDEO_AVAILABLE', 'SEASON_ID', 'Player_ID']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"IMPACT ASSESSMENT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "critical_missing = missing_df[missing_df['Column'].isin(critical_stats)]\n",
    "if len(critical_missing) > 0:\n",
    "    print(f\"CRITICAL stats missing: {critical_missing['Missing'].sum()}\")\n",
    "    print(critical_missing.to_string(index=False))\n",
    "else:\n",
    "    print(f\"CRITICAL stats (PTS, REB, AST, MIN): 0 missing\")\n",
    "\n",
    "important_missing = missing_df[missing_df['Column'].isin(important_stats)]\n",
    "if len(important_missing) > 0:\n",
    "    print(f\"\\nIMPORTANT stats missing: {important_missing['Missing'].sum()}\")\n",
    "    print(important_missing.to_string(index=False))\n",
    "else:\n",
    "    print(f\"IMPORTANT stats (shooting, defense): 0 missing\")\n",
    "\n",
    "contextual_missing = missing_df[missing_df['Column'].isin(contextual_stats)]\n",
    "if len(contextual_missing) > 0:\n",
    "    print(f\"\\nCONTEXTUAL stats missing: {contextual_missing['Missing'].sum()}\")\n",
    "    print(contextual_missing.to_string(index=False))\n",
    "else:\n",
    "    print(f\"CONTEXTUAL stats (opponent, location): 0 missing\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"READY FOR MODELING: {'YES' if len(critical_missing) == 0 else 'NO - FIX CRITICAL STATS FIRST'}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
